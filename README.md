# Meu Projeto de IA

Este projeto √© uma API constru√≠da com Flask que utiliza modelos de NLP para realizar tarefas como **resumo de textos** e **perguntas e respostas**. A API pode ser usada para sintetizar informa√ß√µes a partir de textos longos e tamb√©m para responder perguntas baseadas em um contexto fornecido.

## √çndice

- [Meu Projeto de IA](#meu-projeto-de-ia)
  - [√çndice](#√≠ndice)
  - [Tecnologias](#tecnologias)
  - [Instala√ß√£o](#instala√ß√£o)
  - [Depend√™ncias](#depend√™ncias)
  - [Configura√ß√£o dos Modelos](#configura√ß√£o-dos-modelos)
  - [Como Usar](#como-usar)
  - [Rotas da API](#rotas-da-api)
  - [Exemplos de Uso](#exemplos-de-uso)
    - [Resumo de Texto](#resumo-de-texto)
    - [Perguntas e Respostas](#perguntas-e-respostas)
  - [Como Testar a API](#como-testar-a-api)
    - [Usando curl](#usando-curl)
  - [FAQ](#faq)
  - [Contribuindo](#contribuindo)
  - [Links √öteis e Refer√™ncias](#links-√∫teis-e-refer√™ncias)

## Tecnologias

- Python 3.9+
- Flask
- Hugging Face Transformers
- langdetect

## Instala√ß√£o

Clone o reposit√≥rio e acesse a pasta do projeto:

```bash
git clone https://github.com/diegooilv/nlp-api-python.git
cd nlp-api-python
```

Crie e ative um ambiente virtual:

```bash
python -m venv venv
# Linux/macOS
source venv/bin/activate
# Windows
venv\Scripts\activate
```

Instale as depend√™ncias:

```bash
pip install -r requirements.txt
```

## Depend√™ncias

O arquivo [`requirements.txt`](requirements.txt) cont√©m todas as bibliotecas utilizadas e suas vers√µes:

## Configura√ß√£o dos Modelos

Os modelos de IA s√£o carregados uma √∫nica vez na inicializa√ß√£o da aplica√ß√£o, para uso em **summarization** e **question-answering**:

```python
from transformers import pipeline

print("üîÑ Carregando modelos em Portugu√™s (CPU-only)...")

# Summariza√ß√£o leve
resumidor = pipeline(
    "summarization",
    model="rhaymison/flan-t5-portuguese-small-summarization",
    tokenizer="rhaymison/flan-t5-portuguese-small-summarization",
    device=-1,                    # for√ßa CPU
    framework="pt",               # PyTorch
    max_length=512,               # ajuste conforme necessidade
    min_length=30,
    do_sample=False
)

# QA por extra√ß√£o de trecho
modelo_qa = pipeline(
    "question-answering",
    model="mrm8488/bert-base-portuguese-cased-finetuned-squad-v1-pt",
    tokenizer="mrm8488/bert-base-portuguese-cased-finetuned-squad-v1-pt",
    device=-1                     # for√ßa CPU
)
```

## Como Usar

Inicie o servidor Flask:

```bash
flask run
# ou
python index.py
```

Acesse a API em `http://localhost:5000`.

## Rotas da API

- **POST /resumo**

  - **Descri√ß√£o**: Recebe um texto e retorna um resumo.
  - **Corpo da requisi√ß√£o (JSON)**:
    ```json
    { "texto": "Texto longo para ser resumido." }
    ```
  - **Resposta (JSON)**:
    ```json
    { "resumo": "Texto resumido." }
    ```

- **POST /perguntar**
  - **Descri√ß√£o**: Recebe um texto (`contexto`) e uma pergunta, retornando a resposta extra√≠da do texto.
  - **Corpo da requisi√ß√£o (JSON)**:
    ```json
    {
      "contexto": "Texto onde a resposta est√° contida.",
      "pergunta": "Qual √© a capital do Brasil?"
    }
    ```
  - **Resposta (JSON)**:
    ```json
    { "resposta": "Bras√≠lia" }
    ```

## Exemplos de Uso

### Resumo de Texto

**Entrada**:

```json
{
  "texto": "O Brasil √© o maior pa√≠s da Am√©rica do Sul, conhecido por sua diversidade cultural e geogr√°fica."
}
```

**Sa√≠da**:

```json
{
  "resumo": "O Brasil √© o maior pa√≠s da Am√©rica do Sul, conhecido por sua diversidade cultural e geogr√°fica."
}
```

### Perguntas e Respostas

**Entrada**:

```json
{
  "contexto": "Cristiano Ronaldo venceu a Bola de Ouro cinco vezes, em 2008, 2013, 2014, 2016 e 2017.",
  "pergunta": "Quantas Bolas de Ouro Cristiano Ronaldo tem?"
}
```

**Sa√≠da**:

```json
{
  "resposta": "cinco"
}
```

## Como Testar a API

### Usando curl

- **Resumo**:

  ```bash
  curl -X POST http://localhost:5000/resumo \
    -H "Content-Type: application/json" \
    -d '{"texto": "Texto longo para ser resumido."}'
  ```

- **Perguntas**:
  ```bash
  curl -X POST http://localhost:5000/pergunta \
    -H "Content-Type: application/json" \
    -d '{"contexto": "O Brasil √© o maior pa√≠s da Am√©rica do Sul. Sua capital √© Bras√≠lia.", "pergunta": "Qual √© a capital do Brasil?"}'
  ```

## FAQ

**P: Qual modelo de NLP voc√™s est√£o usando?**  
R: Para resumo: `rhaymison/flan-t5-portuguese-small-summarization`; para QA: `mrm8488/bert-base-portuguese-cased-finetuned-squad-v1-pt`.

**P: Preciso de GPU para rodar?**  
R: N√£o. O c√≥digo for√ßa o uso de CPU (`device=-1`).

## Contribuindo

Se quiser contribuir, abra um issue ou envie um pull request. Sempre atualize a documenta√ß√£o antes de submeter.

## Links √öteis e Refer√™ncias

- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [Flask Documentation](https://flask.palletsprojects.com/)
